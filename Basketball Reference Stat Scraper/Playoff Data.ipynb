{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def remove_multiindex(df: pd.DataFrame):\n",
    "    return df.droplevel(level=0, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# link for extract html data\n",
    "def getdata(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1980 data from existing file.\n",
      "Read 1981 data from existing file.\n",
      "Read 1982 data from existing file.\n",
      "Read 1983 data from existing file.\n",
      "Read 1984 data from existing file.\n",
      "Read 1985 data from existing file.\n",
      "Read 1986 data from existing file.\n",
      "Read 1987 data from existing file.\n",
      "Read 1988 data from existing file.\n",
      "Read 1989 data from existing file.\n",
      "Read 1990 data from existing file.\n",
      "Read 1991 data from existing file.\n",
      "Read 1992 data from existing file.\n",
      "Read 1993 data from existing file.\n",
      "Read 1994 data from existing file.\n",
      "Read 1995 data from existing file.\n",
      "Read 1996 data from existing file.\n",
      "Read 1997 data from existing file.\n",
      "Read 1998 data from existing file.\n",
      "Read 1999 data from existing file.\n",
      "Read 2000 data from existing file.\n",
      "Read 2001 data from existing file.\n",
      "Read 2002 data from existing file.\n",
      "Read 2003 data from existing file.\n",
      "Read 2004 data from existing file.\n",
      "Read 2005 data from existing file.\n",
      "Read 2006 data from existing file.\n",
      "Read 2007 data from existing file.\n",
      "Read 2008 data from existing file.\n",
      "Read 2009 data from existing file.\n",
      "Read 2010 data from existing file.\n",
      "Read 2011 data from existing file.\n",
      "Read 2012 data from existing file.\n",
      "Read 2013 data from existing file.\n",
      "Read 2014 data from existing file.\n",
      "Read 2015 data from existing file.\n",
      "Read 2016 data from existing file.\n",
      "Read 2017 data from existing file.\n",
      "Read 2018 data from existing file.\n",
      "Read 2019 data from existing file.\n",
      "Read 2020 data from existing file.\n",
      "Read 2021 data from existing file.\n",
      "Read 2022 data from existing file.\n",
      "2023 Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create an empty DataFrame to store data from all years\n",
    "all_years_data = pd.DataFrame()\n",
    "\n",
    "# Inside the loop for each year\n",
    "for year in range(1980, datetime.now().year):\n",
    "    # Construct the filename for the CSV file\n",
    "    csv_filename = f'playoffs/{year}_player_playoff_stats.csv'\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(csv_filename):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        year_data = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "        # Add a 'Year' column to the DataFrame\n",
    "        year_data['Year'] = year\n",
    "\n",
    "        # Concatenate the data for the current year to the all_years_data DataFrame\n",
    "        all_years_data = pd.concat([all_years_data, year_data], ignore_index=True)\n",
    "        print(f'Read {year} data from existing file.')\n",
    "    else:\n",
    "        # Query the data and process it (if the file doesn't exist)\n",
    "        df = pd.read_html(getdata(f'https://www.basketball-reference.com/playoffs/NBA_{year}_per_game.html'))[0]\n",
    "        df_adv = pd.read_html(getdata(f'https://www.basketball-reference.com/playoffs/NBA_{year}_advanced.html'))[0]\n",
    "\n",
    "        # Drop rows with header information\n",
    "        df = df.drop(df[df['Player'] == 'Player'].index)\n",
    "        df_adv = df_adv.drop(df_adv[df_adv['Player'] == 'Player'].index)\n",
    "\n",
    "        # Merge the DataFrames\n",
    "        new = pd.merge(df, df_adv, on=['Player', 'Age', 'Tm', 'Pos'])\n",
    "\n",
    "        # Define column lists\n",
    "        player_stats_list = ['Player', 'Pos', 'Age', 'Tm', 'G_x', 'GS', 'MP_x', 'FG', 'FGA',\n",
    "                             'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
    "                             'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS',\n",
    "                             'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%',\n",
    "                             'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS',\n",
    "                             'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "\n",
    "        player_stats_list_correct = ['Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%',\n",
    "                                     '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%',\n",
    "                                     'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PER',\n",
    "                                     'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%',\n",
    "                                     'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM',\n",
    "                                     'VORP']\n",
    "\n",
    "        # Select columns and set column names\n",
    "        new = new[player_stats_list]\n",
    "        new.columns = player_stats_list_correct\n",
    "\n",
    "        # Remove duplicate rows based on 'Player' column\n",
    "        new = new.drop_duplicates(subset='Player', keep=False).reset_index(drop=True)\n",
    "\n",
    "        # Fill NaN values with 0\n",
    "        new.fillna(value=0, inplace=True)\n",
    "\n",
    "        # Add a 'Year' column\n",
    "        new['Year'] = year\n",
    "\n",
    "        # Concatenate the data for the current year to the all_years_data DataFrame\n",
    "        all_years_data = pd.concat([all_years_data, new], ignore_index=True)\n",
    "\n",
    "        # Save the processed DataFrame to the CSV file\n",
    "        new.to_csv(csv_filename)\n",
    "        print(year, 'Complete')\n",
    "\n",
    "# After the loop, you can work with the 'all_years_data' DataFrame\n",
    "all_years_data.to_csv(f'playoffs/all_player_playoff_stats.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}